#
# General system settings
#
- name: enable EPEL yum repo
  package:
    name: epel-release

- name: enable Code Ready Block required by epel
  community.general.dnf_config_manager:
    name: crb
    state: enabled

- name: required packages
  package:
    name:
      - ca-certificates
      - screen
      - tmux
      - htop
      - iotop
      - chrony
      - netcdf
      - postfix
      - git

- name: mail relay config
  template:
    src: postfix/main.cf
    dest: /etc/postfix/main.cf
  notify: reload postfix

- name: mail aliases
  template:
    src: postfix/aliases
    dest: /etc/aliases
  register: newalias

- name: newaliases
  shell: /usr/bin/newaliases
  when: newalias.changed

- name: chrony.conf.j2
  template:
    src: chrony.conf.j2
    dest: /etc/chrony.conf.j2
  notify:
    restart chronyd

- name: chrony service
  service:
    name: chronyd
    state: started
    enabled: true

#
# Permission structures to allow selected users to manage data
#
- name: user datag
  user:
    name: datag
    uid: "{{datag_uid}}"

- name: Set UID range for human users
  lineinfile:
    path: /etc/login.defs
    regexp: "^UID_MAX"
    line: UID_MAX 1099 # reduce from default of 60000, which overlaps with our system users

- name: Set GID range for human users
  lineinfile:
    path: /etc/login.defs
    regexp: "^GID_MAX"
    line: GID_MAX 1099 # reduce from default of 60000, which overlaps with our system users

- name: user accounts
  user:
    name: "{{item.key}}"
    uid: "{{item.value}}"
    groups: datag
    append: yes
  loop: "{{datag_users | dict2items}}"


#
# Directories
#
- name: parent of production and user data dirs
  file:
    path: "{{dataset_parent_dir}}"
    state: directory
    owner: root
    group: root
    mode: u=rwx,g=rx,o=rx

- name: data dir
  file:
    path: "{{data_dir}}"
    state: directory
    owner: datag
    group: datag
    mode: u=rwx,g=rwxs,o=rx

- name: datalib dir
  file:
    path: "{{dldir}}"
    state: directory

- name: datalib etc dir
  file:
    path: "{{dldir}}/etc"
    state: directory

- name: DL user dirs parent
  file:
    path: "{{dl_homes_dir}}"
    state: directory
    owner: root
    group: root
    mode: u=rwx,g=rx,o=rx

- name: DL user dirs
  file:
    path: "{{dl_homes_dir}}/{{item}}"
    state: directory
    owner: "{{item}}"
    group: "{{item}}"
    mode: u=rwx,g=rx,o=rx
  with_items: "{{datag_users}}"

- name: DL user homes
  file:
    path: "{{dl_homes_dir}}/{{item}}/DataCatalog"
    state: directory
    owner: "{{item}}"
    group: "{{item}}"
    mode: u=rwx,g=rx,o=rx
  with_items: "{{datag_users}}"

#
# Docker and docker-compose
#
- name: docker dir
  file:
    state: directory
    path: "{{docker_dir}}"
    mode: "u=rwx,g=x,o=x"

- name: docker dir symlink
  file:
    state: link
    src: "{{docker_dir}}"
    dest: /var/lib/docker
  when: docker_dir != "/var/lib/docker"

- name: install docker-ce repository
  get_url:
    url: https://download.docker.com/linux/centos/docker-ce.repo
    dest: /etc/yum.repos.d/docker-ce.repo

- name: uninstall older versions of docker from original installs
  package:
    name:
      - docker-ce-3:26.0.2-1.el9
      - docker-ce-cli-1:26.0.2-1.el9
      - containerd.io-1.6.31-3.1.el9
      - docker-buildx-plugin-0.14.0-1.el9
      - docker-compose-plugin-2.26.1-1.el9
      - python3-requests
    state: absent

- name: install docker-ce
  # latest stable versions as of 3/7/25
  # installing docker-ce installs the appropriate dependencies that were previously defined here:
  # - docker-ce-cli, containerd-io, docker-buildx-plugin, docker-compose-plugin
  package:
    name:
      # let docker-ce determine the corresponding packages it requires
      - docker-ce-3:28.0.1-1.el9

- name: docker config file
  template:
    src: docker_daemon.j2
    dest: /etc/docker/daemon.json
  notify: restart docker

- name: start and enable docker
  service:
    name: docker
    state: started
    enabled: true

- name: docker login
  docker_login:
    username: iridlserver
    password: "{{docker_hub_access_token}}"
  when: docker_hub_access_token is defined
  # Intentionally not logging out. The (read-only) access token is
  # stored unencrypted on the server, and we're ok with that.

- name: maproom-dev image
  docker_image:
    name: iridl/maproom-dev:{{maproom_dev_version}}
    source: pull

#
# squid
#
- name: squid log rotation cron job
  cron:
    name: squid log rotation
    user: root
    minute: "0"
    hour: "0"
    job: docker exec {{compose_project_name}}_squid_1 squid -k rotate

- name: squid group
  group:
    name: squid
    gid: 23 # the UID/GID used by the CentOS squid packages

- name: squid user
  user:
    name: squid
    uid: 23
    shell: /sbin/nologin
    create_home: no

- name: squid config directory
  file:
    path: "{{squid_config_dir}}"
    state: directory

- name: squid.conf
  template:
    src: squid.conf
    dest: "{{squid_config_dir}}/squid.conf"
  notify: restart squid

#
# git and access to git repos
#
- name: install git
  yum:
    name: git

- name: /root/.ssh
  # Necessary when using sudo, as in vagrant. Works around a bug in
  # the known_hosts module, which ought to create the directory if it
  # doesn't exist.
  file:
    path: /root/.ssh
    state: directory
    mode: '0700'

# The git hosts' ssh host key. Find this with the following
# command, substituting the name of your git host for
# bitbucket.org:
# ssh-keyscan bitbucket.org 2>/dev/null
# This is a public key, not a secret, so it's ok to store here.

- name: add host keys to ssh_known_hosts for git repositories
  known_hosts:
    name: "{{item.host}}"
    key: "{{item.key}}"
  # These are public (host) keys, not secrets, so no need to encrypt them.
  with_items:
    - host: bitbucket.org
      key: bitbucket.org ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIIazEu89wgQZ4bqs3d63QSMzYVa0MuJ2e2gKTKqu+UUO

    - host: github.com
      key: github.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOMqqnkVzrm0SdG6UOoqKLsabgH5C9okWi0dh2l9GKJl

#
# set up git access keys
#

- name: ssh access key directory
  # let's keep all data library files together
  file:
    path: "{{dldir}}/ssh"
    state: directory
    mode: '0700'

- set_fact:
    git_key_file_prefix: "{{dldir}}/ssh/id_rsa-git-"
    git_ssh_prefix: "/usr/local/bin/ssh-git-"
    repo_items: "{{ [ dlentries_repo, maproom_repo ] + ([ python_maproom_repo ] if python_maproom_repo is defined else []) }}"

- name: set up git ssh private keys
  template:
    src: private_key.j2
    dest: "{{ dldir }}/ssh/id_rsa-git-{{ item.name }}"
    mode: "0600"
  with_items: "{{ repo_items }}"
  no_log: true

- name: set up git access keys
  template:
    src: ssh-git.j2
    dest: "/usr/local/bin/ssh-git-{{ item.name }}"
    mode: "0744"
  with_items: "{{ repo_items }}"
  no_log: true


#
# Scripts for managing data
#
- set_fact:
    update_script: /usr/local/bin/update_datalib

- name: update script
  template:
    dest: "{{update_script}}"
    mode: '0755'
    src: "update_datalib"

- name: datag sudoers config
  copy:
    content: |
      Defaults secure_path = /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin
      %datag ALL=(root) NOPASSWD: {{update_script}}
    dest: /etc/sudoers.d/datag_update
    mode: '0400'

- name: sql import dir
  file:
    path: "{{sql_dir}}"
    state: directory
    owner: datag
    group: datag
    mode: u=rwx,g=rwxs,o=rx

- name: sql import script
  copy:
    content: |
      #!/usr/bin/bash -l

      docker exec -it {{compose_project_name}}_postgres_1 /usr/local/bin/entrypoint.sh execsql iridb
    dest: /usr/local/bin/sql_exec
    mode: '0744'

- name: sql command script
  copy:
    content: |
      #!/usr/bin/bash -l

      if [[ -t 0 ]]; then  # input is coming from an interactive terminal
        tty_arg=-t
      fi
      docker exec -i $tty_arg {{compose_project_name}}_postgres_1 psql -U postgres iridb
    dest: /usr/local/bin/sql_interactive
    mode: '0744'

- name: sql sudoers config
  copy:
    content: |
      %datag ALL=(root) NOPASSWD: /usr/local/bin/sql_exec
      %datag ALL=(root) NOPASSWD: /usr/local/bin/sql_interactive
    dest: /etc/sudoers.d/datag_sql
    mode: '0400'


#
# ingrid
#
- name: ingrid config directory
  file:
    path: "{{ingrid_config_dir}}"
    state: directory

- name: install ingrid localdefs.tex
  template:
    src: ingrid-localdefs.tex
    dest: "{{ingrid_config_dir}}/localdefs.tex"
  notify: restart ingrid

- name: ingrid cleantmp cron job
  cron:
    name: cleantmp
    user: root
    minute: "2,7,12,17,22,27,32,37,42,47,52,57"
    job: docker exec -u {{ingrid_uid}} {{compose_project_name}}_ingrid_1 /opt/ingrid/bin/cleantmp.pl {{ admin_emails | join(" ")}}

- name: ingrid scanproc cron job
  cron:
    name: scanproc
    user: root
    minute: "*/15"
    job: "docker exec {{compose_project_name}}_ingrid_1 /opt/ingrid/bin/scanproc.pl /dev/null 2>&1"



#
# put it all together with docker-compose
#
- name: docker-compose project dir
  file:
    path: "{{compose_project_dir}}"
    state: directory

- name: docker-compose.yaml
  template:
    src: docker-compose.yaml.j2
    dest: "{{compose_project_dir}}/docker-compose.yaml"

- name: run update script
  command: "/usr/bin/bash -x {{update_script}} --build-classic"
  when: run_update_script | bool
  register: update_script

- block:
  - debug:
      msg: "{{update_script.stderr_lines}}"

  - debug:
      msg: "{{update_script.stdout_lines}}"
  when: update_script is not skipped

- name: Update docker-compose state for services pulled from registries
  community.docker.docker_compose_v2:
    project_src: "{{compose_project_dir}}"
    pull: missing
    remove_orphans: yes
    services:
      - squid
      - maproom
      - postgres
      - ingrid
  register: docker_compose_result

- debug:
    msg: "{{docker_compose_result}}"
    verbosity: 2

- name: Update docker-compose state for locally built services
  community.docker.docker_compose_v2:
    project_src: "{{compose_project_dir}}"
    pull: never
    remove_orphans: yes
    services:
      - pymaproom
  register: docker_compose_result
  when: python_maproom_repo is defined

- debug:
    msg: "{{docker_compose_result.actions}}"
  when: python_maproom_repo is defined

#
# Tools for managing PyCPT forecasts
#
- name: generate-forecasts script
  template:
    src: generate-forecasts
    dest: /usr/local/bin/generate-forecasts
    mode: ugo+x

- name: upload-forecasts script
  template:
    src: upload-forecasts
    dest: /usr/local/bin/upload-forecasts
    mode: ugo+x


- name: clean up files from old locations
  file:
    path: "{{item}}"
    state: absent
  with_items:
    - "{{dldir}}/ssh/id_rsa-git"
    - /usr/local/bin/ssh-git
    - "{{build_dir}}/maproom_src"
    - "{{build_dir}}/python_maproom_src"


# TODO need smarter criteria for pruning old images; this prunes the
# latest maproom-dev, which then gets re-downloaded on every maproom
# build.
# - name: remove unused docker images
#   docker_prune:
#     images: yes
#     images_filters:
#       dangling: false
#   vars:
#     ansible_python_interpreter: "{{docker_python}}"


#
# Flush handlers, then run tests.
#
# TODO: Ansible gets service restarts wrong. If a playbook crashes
# after a notify but before running the handler, then the handler
# doesn't get triggered on the next run. Stop using handlers and do it
# right: touch a file when the service needs to be restarted, add a
# task that checks for that file and, if it exists, restarts the
# service and then removes the file.

- meta: flush_handlers

- name: service tests
  uri:
    url: http://{{test_host}}:{{test_port}}{{item}}
    headers:
      Cache-Control: no-cache # force squid to talk to the backend
  retries: 5
  delay: 1
  register: uri_result
  until: uri_result is success
  delegate_to: localhost
  become: false
  with_items:
    - /
    - /expert  # ingrid
    - /SOURCES/ # verify data volume is mounted
    - /home/{{(datag_users.keys() | list)[0]}}/
    - /maproom/
  changed_when: no
  check_mode: no # run even in check mode

- name: test outbound proxy
  command: 'docker exec {{compose_project_name}}_ingrid_1 bash -c "curl --silent --header \"Cache-Control: no-cache\" -o /dev/null -w %{http_code} google.com"'
  register: outbound_test
  check_mode: no
  changed_when: no
  failed_when: outbound_test.stdout != "301"

- name: verify that ingrid can talk to db
  uri:
    url: http://{{test_host}}:{{test_port}}/IRIDB/(select%20count(*)%20from%20nosuchtable)/openquery/
    headers:
      Cache-Control: no-cache
    return_content: yes
  retries: 5
  delay: 5
  register: result
  until: result is success
  delegate_to: localhost
  become: false
  # If we can't talk to the db then we get a different error message.
  # Once we have a test db fixture, change the test to look for an actual table.
  failed_when: "'ERROR:  relation \"nosuchtable\" does not exist' not in result.content"
  check_mode: no

- name: verify that python_maproom is running
  uri:
    url: http://{{test_host}}:{{test_port}}/python_maproom/health
    headers:
      Cache-Control: no-cache
    return_content: yes
  retries: 5
  delay: 1
  register: result
  until: result.content_type == "application/json" and result.json.status == "healthy" and result.json.name == "python_maproom"
  delegate_to: localhost
  become: false
  changed_when: no
  check_mode: no
  when: python_maproom_repo is defined

- name: verify that chronyd has synchronized with a time server
  shell: chronyc sources | grep '^\^\*'
  register: chronyc_result
  retries: 6
  until: chronyc_result is success
  delay: 10
  changed_when: no
  check_mode: no # run even in check mode
